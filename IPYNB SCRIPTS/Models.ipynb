{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record: 4-3\n",
    "#Parlay Record: 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Player Averages vs every team\n",
    "import pandas as pd\n",
    "from nba_api.stats.endpoints import playergamelog\n",
    "from nba_api.stats.static import players\n",
    "\n",
    "# Step 1: Get player game log stats for the last 5 years\n",
    "def get_player_gamelog(player_id, seasons):\n",
    "    all_games = []\n",
    "    for season in seasons:\n",
    "        gamelog = playergamelog.PlayerGameLog(player_id=player_id, season=season).get_data_frames()[0]\n",
    "        all_games.append(gamelog)\n",
    "    return pd.concat(all_games, ignore_index=True)\n",
    "\n",
    "# Step 5: Calculate the averages for the player against each team\n",
    "def calculate_averages_vs_teams(player_data):\n",
    "    # Create a column for the opponent's team abbreviation\n",
    "    player_data['OPPONENT'] = player_data['MATCHUP'].apply(lambda x: x.split()[2])  # Extracting opponent team\n",
    "\n",
    "    # Convert WL to numerical values: W = 1, L = 0\n",
    "    player_data['WL'] = player_data['WL'].map({'W': 1, 'L': 0})\n",
    "\n",
    "    averages = player_data.groupby('OPPONENT').agg({\n",
    "        'WL': 'mean',\n",
    "        'MIN': 'mean',\n",
    "        'FGM': 'mean',\n",
    "        'FGA': 'mean',\n",
    "        'FG_PCT': 'mean',\n",
    "        'FG3M': 'mean',\n",
    "        'FG3A': 'mean',\n",
    "        'FG3_PCT': 'mean',\n",
    "        'FTM': 'mean',\n",
    "        'FTA': 'mean',\n",
    "        'FT_PCT': 'mean',\n",
    "        'OREB': 'mean',\n",
    "        'DREB': 'mean',\n",
    "        'REB': 'mean',\n",
    "        'AST': 'mean',\n",
    "        'STL': 'mean',\n",
    "        'BLK': 'mean',\n",
    "        'TOV': 'mean',\n",
    "        'PF': 'mean',\n",
    "        'PTS': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    averages.rename(columns={'WL': 'Win_Loss_Ratio'}, inplace=True)\n",
    "\n",
    "    return averages\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Get player and team data\n",
    "    player_name = input(\"Enter a player's full name (e.g., LeBron James): \")\n",
    "    nba_players = players.get_players()\n",
    "\n",
    "    # Find player ID\n",
    "    player_id = None\n",
    "    for player in nba_players:\n",
    "        if player['full_name'].lower() == player_name.lower():\n",
    "            player_id = player['id']\n",
    "            break\n",
    "\n",
    "    if player_id is None:\n",
    "        print(\"Player not found.\")\n",
    "        return\n",
    "\n",
    "    # Seasons to retrieve data for\n",
    "    seasons = ['2024-25','2023-24','2022-23']\n",
    "\n",
    "    # Get player game logs for these seasons\n",
    "    player_data = get_player_gamelog(player_id, seasons)\n",
    "\n",
    "    # Calculate player averages against each team\n",
    "    team_averages = calculate_averages_vs_teams(player_data)\n",
    "\n",
    "    # Display final data\n",
    "    print(team_averages)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from nba_api.stats.static import players, teams\n",
    "from nba_api.stats.endpoints import playergamelog, commonteamroster\n",
    "import time\n",
    "from requests.exceptions import ReadTimeout, ConnectionError\n",
    "\n",
    "def get_team_roster(team_abbreviation):\n",
    "    try:\n",
    "        team_info = teams.find_team_by_abbreviation(team_abbreviation)\n",
    "        if not team_info:\n",
    "            raise ValueError(f\"Team '{team_abbreviation}' not found.\")\n",
    "        \n",
    "        team_id = team_info['id']\n",
    "        roster = commonteamroster.CommonTeamRoster(team_id=team_id).get_data_frames()[0]\n",
    "        return roster['PLAYER'].tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting roster: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_player_data(player_name, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            player_dict = players.find_players_by_full_name(player_name)\n",
    "            if not player_dict:\n",
    "                print(f\"Player '{player_name}' not found.\")\n",
    "                return None\n",
    "            \n",
    "            player_id = player_dict[0]['id']\n",
    "            \n",
    "            # Get data for both seasons\n",
    "            current_season = playergamelog.PlayerGameLog(\n",
    "                player_id=player_id, \n",
    "                season='2024-25',\n",
    "                timeout=60\n",
    "            ).get_data_frames()[0]\n",
    "            \n",
    "            previous_season = playergamelog.PlayerGameLog(\n",
    "                player_id=player_id, \n",
    "                season='2023-24',\n",
    "                timeout=60\n",
    "            ).get_data_frames()[0]\n",
    "            \n",
    "            # Combine the data\n",
    "            combined_data = pd.concat([current_season, previous_season], ignore_index=True)\n",
    "            \n",
    "            print(f\"Data fetched successfully for {player_name}\")\n",
    "            print(f\"Total games: {len(combined_data)} (Current season: {len(current_season)}, Previous season: {len(previous_season)})\")\n",
    "            \n",
    "            return combined_data\n",
    "            \n",
    "        except (ReadTimeout, ConnectionError) as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Attempt {attempt + 1} failed for {player_name}. Retrying...\")\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                print(f\"Failed to fetch data for {player_name} after {max_retries} attempts\")\n",
    "                return None\n",
    "\n",
    "def preprocess_game_log(game_log):\n",
    "    # Convert date to datetime\n",
    "    game_log['GAME_DATE'] = pd.to_datetime(game_log['GAME_DATE'])    \n",
    "    # Create home/away indicator\n",
    "    game_log['HOME_AWAY'] = np.where(game_log['MATCHUP'].str.contains('@'), 'Away', 'Home')\n",
    "    \n",
    "    # Convert columns to float\n",
    "    for col in ['PTS', 'REB', 'AST', 'BLK', 'STL', 'FGM', 'FGA', 'FG_PCT', \n",
    "                'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', \n",
    "                'OREB', 'DREB', 'TOV', 'PF', 'PLUS_MINUS']:\n",
    "        game_log[col] = game_log[col].astype(float)\n",
    "\n",
    "    # Sort by date before calculating rolling averages\n",
    "    game_log = game_log.sort_values('GAME_DATE', ascending=True)\n",
    "\n",
    "    # Create rolling averages for recent games\n",
    "    rolling_window = 5\n",
    "    for stat in ['PTS', 'REB', 'AST', 'BLK', 'STL', 'FGM', 'FGA', 'FTM', 'OREB', 'DREB']:\n",
    "        game_log[f'AVG_{stat}'] = game_log[stat].rolling(window=rolling_window).mean()\n",
    "\n",
    "    # Drop NaN values that may have been created by rolling averages\n",
    "    game_log.dropna(inplace=True)\n",
    "\n",
    "    return game_log\n",
    "\n",
    "# ... (keep all previous imports and functions up to preprocess_game_log) ...\n",
    "\n",
    "def train_model(game_log):\n",
    "    # Select features and target variable\n",
    "    features = game_log[['AVG_PTS', 'AVG_REB', 'AVG_AST', 'AVG_BLK', 'AVG_STL', \n",
    "                         'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', \n",
    "                         'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'TOV', 'PF', 'PLUS_MINUS']]\n",
    "    target = game_log['PTS']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create and train the linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions and calculate the mean squared error\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Test MSE: {mse:.2f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_performance_against_team(model, game_log, opponent_team):\n",
    "    # Filter for games against the specific opponent\n",
    "    opponent_games = game_log[game_log['MATCHUP'].str.contains(opponent_team)]\n",
    "    \n",
    "    if opponent_games.empty:\n",
    "        print(f\"No previous games found against team: {opponent_team}.\")\n",
    "        return None\n",
    "\n",
    "    # Calculate averages for the opponent games\n",
    "    avg_stats = opponent_games[['PTS', 'REB', 'AST', 'BLK', 'STL', \n",
    "                               'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', \n",
    "                               'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'TOV', \n",
    "                               'PF', 'PLUS_MINUS']].mean()\n",
    "\n",
    "    # Prepare input features for prediction\n",
    "    features = pd.DataFrame({\n",
    "        'AVG_PTS': [avg_stats['PTS']],\n",
    "        'AVG_REB': [avg_stats['REB']],\n",
    "        'AVG_AST': [avg_stats['AST']],\n",
    "        'AVG_BLK': [avg_stats['BLK']],\n",
    "        'AVG_STL': [avg_stats['STL']],\n",
    "        'FGM': [avg_stats['FGM']],\n",
    "        'FGA': [avg_stats['FGA']],\n",
    "        'FG_PCT': [avg_stats['FG_PCT']],\n",
    "        'FG3M': [avg_stats['FG3M']],\n",
    "        'FG3A': [avg_stats['FG3A']],\n",
    "        'FG3_PCT': [avg_stats['FG3_PCT']],\n",
    "        'FTM': [avg_stats['FTM']],\n",
    "        'FTA': [avg_stats['FTA']],\n",
    "        'FT_PCT': [avg_stats['FT_PCT']],\n",
    "        'OREB': [avg_stats['OREB']],\n",
    "        'DREB': [avg_stats['DREB']],\n",
    "        'TOV': [avg_stats['TOV']],\n",
    "        'PF': [avg_stats['PF']],\n",
    "        'PLUS_MINUS': [avg_stats['PLUS_MINUS']]\n",
    "    })\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_points = model.predict(features)[0]\n",
    "    return predicted_points\n",
    "\n",
    "def main():\n",
    "    # Get team abbreviation from user\n",
    "    team_abbrev = input(\"Enter team abbreviation (e.g., 'NYK' for Knicks): \")\n",
    "    opponent_team = input(\"Enter the opponent team abbreviation (e.g., 'LAC'): \")\n",
    "    \n",
    "    # Get roster\n",
    "    roster = get_team_roster(team_abbrev)\n",
    "    print(f\"\\nAnalyzing {len(roster)} players from {team_abbrev}...\")\n",
    "    \n",
    "    # Store predictions\n",
    "    predictions = {}\n",
    "    \n",
    "    # Process each player\n",
    "    for player_name in roster:\n",
    "        print(f\"\\nProcessing {player_name}...\")\n",
    "        \n",
    "        # Get player data\n",
    "        game_log = get_player_data(player_name)\n",
    "        if game_log is None or len(game_log) < 5:  # Need at least 5 games for rolling averages\n",
    "            print(f\"Insufficient data for {player_name}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Process data and make prediction\n",
    "            processed_log = preprocess_game_log(game_log)\n",
    "            model = train_model(processed_log)\n",
    "            predicted_points = predict_performance_against_team(model, processed_log, opponent_team)\n",
    "            \n",
    "            if predicted_points is not None:\n",
    "                predictions[player_name] = predicted_points\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {player_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nPredicted points against {opponent_team}:\")\n",
    "    print(\"-\" * 50)\n",
    "    for player, points in sorted(predictions.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{player:<30} {points:.1f} points\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monte Carlo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nba_api.stats.static import players, teams\n",
    "from nba_api.stats.endpoints import playergamelog, commonteamroster\n",
    "import time\n",
    "from requests.exceptions import ReadTimeout, ConnectionError\n",
    "\n",
    "def get_team_roster(team_abbreviation):\n",
    "    try:\n",
    "        team_info = teams.find_team_by_abbreviation(team_abbreviation)\n",
    "        if not team_info:\n",
    "            raise ValueError(f\"Team '{team_abbreviation}' not found.\")\n",
    "        \n",
    "        team_id = team_info['id']\n",
    "        roster = commonteamroster.CommonTeamRoster(team_id=team_id).get_data_frames()[0]\n",
    "        return roster['PLAYER'].tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting roster: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_player_data(player_name, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            player_dict = players.find_players_by_full_name(player_name)\n",
    "            if not player_dict:\n",
    "                print(f\"Player '{player_name}' not found.\")\n",
    "                return None\n",
    "            \n",
    "            player_id = player_dict[0]['id']\n",
    "            \n",
    "            # Get data for both seasons\n",
    "            current_season = playergamelog.PlayerGameLog(\n",
    "                player_id=player_id, \n",
    "                season='2024-25',\n",
    "                timeout=60\n",
    "            ).get_data_frames()[0]\n",
    "            \n",
    "            previous_season = playergamelog.PlayerGameLog(\n",
    "                player_id=player_id, \n",
    "                season='2023-24',\n",
    "                timeout=60\n",
    "            ).get_data_frames()[0]\n",
    "            \n",
    "            # Combine the data\n",
    "            combined_data = pd.concat([current_season, previous_season], ignore_index=True)\n",
    "            \n",
    "            print(f\"Data fetched successfully for {player_name}\")\n",
    "            print(f\"Total games: {len(combined_data)} (Current season: {len(current_season)}, Previous season: {len(previous_season)})\")\n",
    "            \n",
    "            return combined_data\n",
    "            \n",
    "        except (ReadTimeout, ConnectionError) as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Attempt {attempt + 1} failed for {player_name}. Retrying...\")\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                print(f\"Failed to fetch data for {player_name} after {max_retries} attempts\")\n",
    "                return None\n",
    "\n",
    "def monte_carlo_simulation(game_log, opponent_team, num_simulations=10000, confidence_level=0.95):\n",
    "    # Filter for games against the specific opponent\n",
    "    opponent_games = game_log[game_log['MATCHUP'].str.contains(opponent_team)]\n",
    "    \n",
    "    if opponent_games.empty:\n",
    "        print(f\"No previous games found against team: {opponent_team}.\")\n",
    "        return None\n",
    "\n",
    "    # Extract stats from games against the opponent\n",
    "    points = opponent_games['PTS'].values\n",
    "    rebounds = opponent_games['REB'].values\n",
    "    assists = opponent_games['AST'].values\n",
    "    \n",
    "    # Calculate mean and standard deviation\n",
    "    mean_points, std_points = points.mean(), points.std() if len(points) > 1 else 0\n",
    "    mean_rebounds, std_rebounds = rebounds.mean(), rebounds.std() if len(rebounds) > 1 else 0\n",
    "    mean_assists, std_assists = assists.mean(), assists.std() if len(assists) > 1 else 0\n",
    "\n",
    "    # Run simulations\n",
    "    simulated_points = np.random.normal(loc=mean_points, scale=std_points, size=num_simulations)\n",
    "    simulated_rebounds = np.random.normal(loc=mean_rebounds, scale=std_rebounds, size=num_simulations)\n",
    "    simulated_assists = np.random.normal(loc=mean_assists, scale=std_assists, size=num_simulations)\n",
    "    \n",
    "    return {\n",
    "        \"points\": {\n",
    "            \"mean\": simulated_points.mean(),\n",
    "            \"median\": np.median(simulated_points),\n",
    "            \"std\": simulated_points.std(),\n",
    "            \"ci_lower\": np.percentile(simulated_points, (1-confidence_level) / 2 * 100),\n",
    "            \"ci_upper\": np.percentile(simulated_points, (1 + confidence_level) / 2 * 100)\n",
    "        },\n",
    "        \"rebounds\": {\n",
    "            \"mean\": simulated_rebounds.mean(),\n",
    "            \"median\": np.median(simulated_rebounds),\n",
    "            \"std\": simulated_rebounds.std(),\n",
    "            \"ci_lower\": np.percentile(simulated_rebounds, (1-confidence_level) / 2 * 100),\n",
    "            \"ci_upper\": np.percentile(simulated_rebounds, (1 + confidence_level) / 2 * 100)\n",
    "        },\n",
    "        \"assists\": {\n",
    "            \"mean\": simulated_assists.mean(),\n",
    "            \"median\": np.median(simulated_assists),\n",
    "            \"std\": simulated_assists.std(),\n",
    "            \"ci_lower\": np.percentile(simulated_assists, (1-confidence_level) / 2 * 100),\n",
    "            \"ci_upper\": np.percentile(simulated_assists, (1 + confidence_level) / 2 * 100)\n",
    "        }\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Get team abbreviation from user\n",
    "    team_abbrev = input(\"Enter team abbreviation (e.g., 'NYK' for Knicks): \")\n",
    "    opponent_team = input(\"Enter the opponent team abbreviation (e.g., 'LAC'): \")\n",
    "    \n",
    "    # Get roster\n",
    "    roster = get_team_roster(team_abbrev)\n",
    "    print(f\"\\nAnalyzing {len(roster)} players from {team_abbrev}...\")\n",
    "    \n",
    "    # Store predictions\n",
    "    all_predictions = {}\n",
    "    \n",
    "    # Process each player\n",
    "    for player_name in roster:\n",
    "        print(f\"\\nProcessing {player_name}...\")\n",
    "        \n",
    "        # Get player data\n",
    "        game_log = get_player_data(player_name)\n",
    "        if game_log is None:\n",
    "            print(f\"No data available for {player_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Run Monte Carlo simulation\n",
    "        predicted_stats = monte_carlo_simulation(game_log, opponent_team)\n",
    "        \n",
    "        if predicted_stats is not None:\n",
    "            all_predictions[player_name] = predicted_stats\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nMonte Carlo Predictions against {opponent_team}:\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Sort players by predicted points\n",
    "    sorted_players = sorted(all_predictions.items(), \n",
    "                          key=lambda x: x[1]['points']['mean'], \n",
    "                          reverse=True)\n",
    "    \n",
    "    for player_name, stats in sorted_players:\n",
    "        print(f\"\\n{player_name}:\")\n",
    "        print(f\"Points:   {stats['points']['mean']:.1f} ± {stats['points']['std']:.1f} \"\n",
    "              f\"[{stats['points']['ci_lower']:.1f}, {stats['points']['ci_upper']:.1f}]\")\n",
    "        print(f\"Rebounds: {stats['rebounds']['mean']:.1f} ± {stats['rebounds']['std']:.1f} \"\n",
    "              f\"[{stats['rebounds']['ci_lower']:.1f}, {stats['rebounds']['ci_upper']:.1f}]\")\n",
    "        print(f\"Assists:  {stats['assists']['mean']:.1f} ± {stats['assists']['std']:.1f} \"\n",
    "              f\"[{stats['assists']['ci_lower']:.1f}, {stats['assists']['ci_upper']:.1f}]\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted PPG\n",
    "\n",
    "from nba_api.stats.static import players\n",
    "from nba_api.stats.endpoints import playergamelog\n",
    "from nba_api.stats.endpoints import commonteamroster\n",
    "from nba_api.stats.static import teams\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# players we are looking for predictions on, use full name, not case-sensitive\n",
    "people = []\n",
    "# players who are on the home team\n",
    "home_players = []\n",
    "\n",
    "# list that will contain the player ids\n",
    "ids = []\n",
    "\n",
    "# dictionary used to determine which team a player is playing against\n",
    "team = {'home': 'MIL'\n",
    "         , 'away': 'UTA'}\n",
    "\n",
    "match_up = {}\n",
    "# pts = -3, ast = -8, reb = -9\n",
    "stat = -3\n",
    "\n",
    "#get home team from input\n",
    "\n",
    "#get away team from input\n",
    "\n",
    "#get stat from input\n",
    "\n",
    "####\n",
    "#Make get players from team a function\n",
    "####\n",
    "\n",
    "#get players on the home team\n",
    "h_team = teams.find_team_by_abbreviation(abbreviation= team['home'])\n",
    "h_id = h_team['id']\n",
    "h_roster = commonteamroster.CommonTeamRoster(team_id= h_id)\n",
    "dfh = h_roster.get_dict()\n",
    "#add the players on the home team to list of people\n",
    "for item in dfh['resultSets'][0]['rowSet']:\n",
    "    people.append(item[3])\n",
    "    home_players.append(item[3])\n",
    "\n",
    "#get players on the away team\n",
    "a_team = teams.find_team_by_abbreviation(abbreviation= team['away'])\n",
    "a_id = a_team['id']\n",
    "a_roster = commonteamroster.CommonTeamRoster(team_id= a_id)\n",
    "dfa = a_roster.get_dict()\n",
    "#add the players on the away team to list of people\n",
    "for item in dfa['resultSets'][0]['rowSet']:\n",
    "    people.append(item[3])\n",
    "\n",
    "# get the player id from full name\n",
    "print(people)\n",
    "for person in people:\n",
    "    # get the player id from their full name\n",
    "    player = players.find_players_by_full_name(person)\n",
    "    person = person.lower()\n",
    "    #print(player)\n",
    "    try:\n",
    "        ids.append(player[0]['id'])\n",
    "    except:\n",
    "        continue\n",
    "    # determine the team a player is playing against based on weather they are home or away\n",
    "    if person in home_players:\n",
    "        match_up[person] = team['away']\n",
    "    else:\n",
    "        match_up[person] = team['home']\n",
    "\n",
    "#print(ids)\n",
    "#print(player[0].keys())\n",
    "#print(match_up)\n",
    "\n",
    "# loop through each pid and make prediction\n",
    "# Make prediction a function\n",
    "for pid in ids:\n",
    "\n",
    "    name = players.find_player_by_id(pid)\n",
    "    lower_name = name['full_name'].lower()\n",
    "\n",
    "    # get the player game log using the nba api\n",
    "    games = playergamelog.PlayerGameLog( player_id=str(pid), season='2023-24' )\n",
    "    # create data frame and dictionary from the game log\n",
    "    p = games.get_data_frames()\n",
    "    test = games.get_dict()\n",
    "\n",
    "\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', 100)\n",
    "    #print(p)\n",
    "\n",
    "\n",
    "    #get the data we will use\n",
    "    i = 0\n",
    "    j = 0\n",
    "    avg_points = 0\n",
    "    points = []\n",
    "    match_up_points = 0\n",
    "    home = []\n",
    "    big_dict = dict()\n",
    "    for row in test['resultSets'][0]['rowSet']:\n",
    "        # calculate the player avg ppg\n",
    "        if test['resultSets'][0]['rowSet'][i][5] != None:\n",
    "            points.append(test['resultSets'][0]['rowSet'][i][stat])\n",
    "            avg_points += test['resultSets'][0]['rowSet'][i][stat]\n",
    "\n",
    "            # calculate the players avg points against this team\n",
    "            if match_up[lower_name] in test['resultSets'][0]['rowSet'][i][4]:\n",
    "                match_up_points += test['resultSets'][0]['rowSet'][i][stat]\n",
    "                j += 1\n",
    "\n",
    "            # Determine weather home or away, 0 is away, home is 1\n",
    "            if '@' in test['resultSets'][0]['rowSet'][i][4]:\n",
    "                home.append(0)\n",
    "            else:\n",
    "                home.append(1)\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    if i != 0:\n",
    "        avg_points = avg_points / i\n",
    "    else:\n",
    "        avg_points = 0\n",
    "    #if player has never played team set matchup points to average\n",
    "    if j != 0:\n",
    "        match_up_points = match_up_points/j\n",
    "    else:\n",
    "        match_up_points = avg_points\n",
    "    #print(points)\n",
    "    #print(avg)\n",
    "    if len(player) == 0:\n",
    "        continue\n",
    "\n",
    "    #################\n",
    "    # prediction model for pts, ast, reb\n",
    "    #\n",
    "    #\n",
    "    ###################\n",
    "\n",
    "    # create our data set\n",
    "    data = {'points': points\n",
    "            , 'average_points': avg_points\n",
    "            , 'home_or_away': home\n",
    "            , 'match_up_points': match_up_points}\n",
    "    df = pd.DataFrame(data)\n",
    "    # do not make a prediction on players who have played less then 10 games\n",
    "    if len(df) < 10:\n",
    "        continue\n",
    "    # Reverse the order of the DataFrame so the most recent game is first in the list\n",
    "    df = df[::-1].reset_index(drop=True)\n",
    "\n",
    "    # Create a new column 'next_game_points' shifted by one to represent the target variable\n",
    "    df['next_game_points'] = df['points'].shift(-1)\n",
    "    # Drop the last row with NaN in 'next_game_points' as there's no information about the next game\n",
    "    df = df.dropna()\n",
    "    #print(df)\n",
    "\n",
    "    # Features and target variable\n",
    "    X = df[['points', 'average_points', 'home_or_away', 'match_up_points']]\n",
    "    y = df['next_game_points']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "    # Create a Linear Regression model\n",
    "    linear_model = LinearRegression()\n",
    "    # Train the model\n",
    "    linear_model.fit(X_train, y_train)\n",
    "    # Make predictions on the test set\n",
    "    predictions_linear = linear_model.predict(X_test)\n",
    "\n",
    "\n",
    "    # Create Random Forest Regressor model\n",
    "    rf_model = RandomForestRegressor()\n",
    "    # Train the model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    # Make predictions on the test set\n",
    "    predictions_rf = rf_model.predict(X_test)\n",
    "\n",
    "    # Evaluate models\n",
    "    mae_linear = mean_absolute_error(y_test, predictions_linear)\n",
    "    mae_rf = mean_absolute_error(y_test, predictions_rf)\n",
    "\n",
    "    # Cross validate the model\n",
    "    # Combine the features and target variable into one DataFrame\n",
    "    cross_data = pd.concat([X, y], axis=1)\n",
    "\n",
    "    # Define the number of folds for cross-validation\n",
    "    num_folds = 5 # You can adjust the number of folds based on your preference\n",
    "\n",
    "    # Set up KFold for cross-validation\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform cross-validation for Linear Regression\n",
    "    linear_mae_cv = cross_val_score(linear_model, X, y, cv=kf, scoring=make_scorer(mean_absolute_error))\n",
    "    # Perform cross-validation for Random Forest Regressor\n",
    "    rf_mae_cv = cross_val_score(rf_model, X, y, cv=kf, scoring=make_scorer(mean_absolute_error))\n",
    "\n",
    "    # Calculate the average cross-validation MAE for each model\n",
    "    avg_linear_mae_cv = linear_mae_cv.mean()\n",
    "    avg_rf_mae_cv = rf_mae_cv.mean()\n",
    "    combined_cv_result = (avg_linear_mae_cv + avg_rf_mae_cv) / 2\n",
    "\n",
    "    # Combine predictions using model averaging\n",
    "    combined_predictions = (predictions_linear + predictions_rf) / 2\n",
    "    # Evaluate the combined predictions\n",
    "    mae_combined = mean_absolute_error(y_test, combined_predictions)\n",
    "\n",
    "    # print the players name\n",
    "    print(name['full_name'])\n",
    "    # print points list and average\n",
    "    print(f'Points in past games: {points}')\n",
    "    print(f'Avg PPG: {avg_points}')\n",
    "    print(f'Avg Match-up PPG: {match_up_points}')\n",
    "\n",
    "    # Now, use the trained model to predict the points for the next game\n",
    "    # Given the last known points and player's average points:\n",
    "    last_known_points = points[0]\n",
    "    print(last_known_points)\n",
    "    player_average = df['average_points'].iloc[-1:]\n",
    "    home = 0\n",
    "    if lower_name in home_players:\n",
    "        home = 1\n",
    "    new_data = pd.DataFrame({'points': last_known_points, 'average_points': player_average,\n",
    "                             'home_or_away': home, 'match_up_points': match_up_points})\n",
    "    predicted_points_linear = linear_model.predict(new_data)\n",
    "    predicted_points_rf = rf_model.predict(new_data)\n",
    "    predicted_points_combined = (linear_model.predict(new_data) + rf_model.predict(new_data)) / 2\n",
    "\n",
    "    # Print results\n",
    "    print('\\nLinear regression predictions:')\n",
    "    print(f'Linear Regression - Mean Absolute Error: {mae_linear}')\n",
    "    print(f'Linear Regression - Cross-Validation Mean Absolute Error: {linear_mae_cv.mean()}')\n",
    "    print(f'Linear Predicted Points for the Next Game: {predicted_points_linear[0]}')\n",
    "    print('\\nRandom Forest Regression Predictions:')\n",
    "    print(f'Random Forest Regression - Mean Absolute Error: {mae_rf}')\n",
    "    print(f'Random Forest Regression - Cross-Validation Mean Absolute Error: {rf_mae_cv.mean()}')\n",
    "    print(f'Random Forest predicted Points for the Next Game: {predicted_points_rf[0]}')\n",
    "    print('\\nCombined Predictions:')\n",
    "    print(f'Combined Predictions - Mean Absolute Error: {mae_combined}')\n",
    "    print(f'Combined Cross-Validation Result: {combined_cv_result}')\n",
    "    print(f'Combined Predicted Points for the Next Game: {predicted_points_combined[0]}')\n",
    "    print('***********************************************************************************\\n')\n",
    "\n",
    "    # Create scatter plot to display accuracy\n",
    "    plot = False\n",
    "    if plot:\n",
    "        # Scatter plot predicted vs actual\n",
    "        plt.scatter(predictions_linear, y_test, label='Linear Regression', color='blue')  # Swap x and y here\n",
    "        plt.scatter(predictions_rf, y_test, label='Random Forest Regression', color='green')  # Swap x and y here\n",
    "        plt.scatter(combined_predictions, y_test, label='Combined Predictions', color='orange')  # Swap x and y here\n",
    "\n",
    "        # Add line of best fit\n",
    "        linear_fit = np.polyfit(predictions_linear, y_test, 1)  # Swap x and y here\n",
    "        rf_fit = np.polyfit(predictions_rf, y_test, 1)  # Swap x and y here\n",
    "        combined_fit = np.polyfit(combined_predictions, y_test, 1)  # Swap x and y here\n",
    "\n",
    "        # Add diagonal line for reference (ideal prediction)\n",
    "        plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red',\n",
    "             label='Ideal Prediction')\n",
    "\n",
    "        # Set labels and title\n",
    "        plt.xlabel('Predicted Points')\n",
    "        plt.ylabel('Actual Points')\n",
    "        plt.title(name['full_name'])\n",
    "\n",
    "        # Add legend\n",
    "        plt.legend()\n",
    "\n",
    "        # Display the plot\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated Deep Learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nba_api.stats.static import players\n",
    "from nba_api.stats.endpoints import playergamelog\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from nba_api.stats.endpoints import commonteamroster\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Function to retrieve the roster of a specific team\n",
    "def get_team_roster(team_id, retries=3):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            team_roster = commonteamroster.CommonTeamRoster(team_id=team_id).get_data_frames()[0]\n",
    "            return team_roster['PLAYER'].tolist()\n",
    "        except requests.ReadTimeout:\n",
    "            if attempt < retries - 1:  # Don't wait after the last attempt\n",
    "                print(f\"Attempt {attempt + 1} failed. Retrying...\")\n",
    "                time.sleep(2)  # Wait a bit before retrying\n",
    "            else:\n",
    "                print(\"Failed to retrieve team roster after multiple attempts.\")\n",
    "                raise\n",
    "\n",
    "# Function to retrieve player data from the NBA API\n",
    "def get_player_data(player_name):\n",
    "    player_dict = players.find_players_by_full_name(player_name)\n",
    "    if not player_dict:\n",
    "        raise ValueError(f\"Player '{player_name}' not found.\")\n",
    "    \n",
    "    player_id = player_dict[0]['id']\n",
    "    game_log = playergamelog.PlayerGameLog(player_id=player_id, season='2023-24').get_data_frames()[0]\n",
    "    return game_log\n",
    "\n",
    "# Preprocessing function for the game logs\n",
    "def preprocess_game_log(game_log):\n",
    "    game_log['GAME_DATE'] = pd.to_datetime(game_log['GAME_DATE'])\n",
    "    game_log['HOME_AWAY'] = np.where(game_log['MATCHUP'].str.contains('@'), 'Away', 'Home')\n",
    "    \n",
    "    for col in ['PTS', 'REB', 'AST', 'BLK', 'STL', 'FGM', 'FGA', 'FG_PCT', \n",
    "                'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', \n",
    "                'OREB', 'DREB', 'TOV', 'PF', 'PLUS_MINUS']:\n",
    "        game_log[col] = game_log[col].astype(float)\n",
    "\n",
    "    rolling_window = 5\n",
    "    for stat in ['PTS', 'REB', 'AST', 'BLK', 'STL', 'FGM', 'FGA', 'FTM', 'OREB', 'DREB']:\n",
    "        game_log[f'AVG_{stat}'] = game_log[stat].rolling(window=rolling_window).mean()\n",
    "\n",
    "    game_log.dropna(inplace=True)\n",
    "\n",
    "    return game_log\n",
    "\n",
    "# Model training function using Deep Learning\n",
    "def train_model(game_log):\n",
    "    features = game_log[['AVG_PTS', 'AVG_REB', 'AVG_AST', 'AVG_BLK', 'AVG_STL', \n",
    "                         'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', \n",
    "                         'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'TOV', 'PF', 'PLUS_MINUS']]\n",
    "    target = game_log[['PTS', 'REB', 'AST']]  \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(3))  # Output for points, rebounds, assists\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Test MSE: {mse:.2f}')\n",
    "\n",
    "    return model, scaler\n",
    "\n",
    "# Function to predict player performance against a specific team\n",
    "def predict_performance_against_team(model, scaler, game_log, opponent_team):\n",
    "    opponent_games = game_log[game_log['MATCHUP'].str.contains(opponent_team)]\n",
    "    \n",
    "    if opponent_games.empty:\n",
    "        print(f\"No previous games found against team: {opponent_team}.\")\n",
    "        return None\n",
    "\n",
    "    avg_stats = opponent_games[['PTS', 'REB', 'AST', 'BLK', 'STL', \n",
    "                                 'FGM', 'FGA', 'FG_PCT', 'FG3M', \n",
    "                                 'FG3A', 'FG3_PCT', 'FTM', 'FTA', \n",
    "                                 'FT_PCT', 'OREB', 'DREB', 'TOV', \n",
    "                                 'PF', 'PLUS_MINUS']].mean()\n",
    "\n",
    "    features = pd.DataFrame({\n",
    "        'AVG_PTS': [avg_stats['PTS']],\n",
    "        'AVG_REB': [avg_stats['REB']],\n",
    "        'AVG_AST': [avg_stats['AST']],\n",
    "        'AVG_BLK': [avg_stats['BLK']],\n",
    "        'AVG_STL': [avg_stats['STL']],\n",
    "        'FGM': [avg_stats['FGM']],\n",
    "        'FGA': [avg_stats['FGA']],\n",
    "        'FG_PCT': [avg_stats['FG_PCT']],\n",
    "        'FG3M': [avg_stats['FG3M']],\n",
    "        'FG3A': [avg_stats['FG3A']],\n",
    "        'FG3_PCT': [avg_stats['FG3_PCT']],\n",
    "        'FTM': [avg_stats['FTM']],\n",
    "        'FTA': [avg_stats['FTA']],\n",
    "        'FT_PCT': [avg_stats['FT_PCT']],\n",
    "        'OREB': [avg_stats['OREB']],\n",
    "        'DREB': [avg_stats['DREB']],\n",
    "        'TOV': [avg_stats['TOV']],\n",
    "        'PF': [avg_stats['PF']],\n",
    "        'PLUS_MINUS': [avg_stats['PLUS_MINUS']],\n",
    "    })\n",
    "\n",
    "    features = scaler.transform(features)\n",
    "    predicted_stats = model.predict(features)[0]\n",
    "    \n",
    "    return predicted_stats\n",
    "\n",
    "\n",
    "\n",
    "# Main function to run the workflow\n",
    "def main():\n",
    "\n",
    "    team_id = \"1610612745\"  # Example team ID for the Los Angeles Lakers\n",
    "    opponent_team = input(\"Enter the opponent team (e.g., 'LAC'): \")\n",
    " \n",
    "    \n",
    "    roster = get_team_roster(team_id)\n",
    "    \n",
    "    predictions = {}\n",
    "    \n",
    "    for player_name in roster:\n",
    "        try:\n",
    "            game_log = get_player_data(player_name)\n",
    "            processed_log = preprocess_game_log(game_log)\n",
    "            model, scaler = train_model(processed_log)\n",
    "            predicted_stats = predict_performance_against_team(model, scaler, processed_log, opponent_team)\n",
    "\n",
    "            if predicted_stats is not None:\n",
    "                predicted_points, predicted_rebounds, predicted_assists = predicted_stats\n",
    "                predictions[player_name] = {\n",
    "                    'Points': predicted_points,\n",
    "                    'Rebounds': predicted_rebounds,\n",
    "                    'Assists': predicted_assists\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {player_name}: {e}\")\n",
    "    \n",
    "    print(\"\\nPredicted performance against\", opponent_team)\n",
    "    for player, stats in predictions.items():\n",
    "        print(f\"{player}: Points: {stats['Points']:.2f}, Rebounds: {stats['Rebounds']:.2f}, Assists: {stats['Assists']:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Networks\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define the neural network architecture with dropout layers\n",
    "def build_neural_network(input_shape, layers=3, neurons=64, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', input_shape=(input_shape,)))  # Input layer\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))  # Hidden layers\n",
    "        model.add(Dropout(dropout_rate))  # Dropout layer for regularization\n",
    "\n",
    "    model.add(Dense(3))  # Output layer for PTS, REB, AST\n",
    "    return model\n",
    "\n",
    "# Compile the neural network with optimizer learning rate parameter\n",
    "def compile_neural_network(model, learning_rate=0.001):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Train the neural network\n",
    "def train_neural_network(features, targets):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Build and compile the neural network\n",
    "    nn_model = build_neural_network(X_train_scaled.shape[1])\n",
    "    nn_model = compile_neural_network(nn_model)\n",
    "\n",
    "    # Train the model\n",
    "    history = nn_model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = nn_model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Test Mean Squared Error: {mse:.2f}')\n",
    "\n",
    "    return nn_model, scaler\n",
    "\n",
    "\n",
    "# Predict player stats against a specific team\n",
    "def predict_player_stats_nn(model, scaler, averages, opponent_abbreviation):\n",
    "    opponent_data = averages[averages['OPPONENT'] == opponent_abbreviation]\n",
    "    if opponent_data.empty:\n",
    "        print(f\"No data available for opponent: {opponent_abbreviation}\")\n",
    "        return None\n",
    "\n",
    "    # Prepare the features for prediction\n",
    "    features = opponent_data.drop(columns=['OPPONENT', 'Win_Loss_Ratio'])\n",
    "    features_scaled = scaler.transform(features)\n",
    "\n",
    "    # Predict the stats using the trained neural network\n",
    "    predictions = model.predict(features_scaled)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Function to build the model for GridSearchCV\n",
    "def create_model(layers=3, neurons=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = build_neural_network(input_shape=10, layers=layers, neurons=neurons, dropout_rate=dropout_rate)  # input_shape is a placeholder, will be dynamically set\n",
    "    model = compile_neural_network(model, learning_rate=learning_rate)\n",
    "    return model\n",
    "\n",
    "# Main function to drive the program\n",
    "def main():\n",
    "    # Get player and team data\n",
    "    player_name = input(\"Enter a player's full name (e.g., LeBron James): \")\n",
    "    nba_players = players.get_players()\n",
    "\n",
    "    # Find player ID\n",
    "    player_id = None\n",
    "    for player in nba_players:\n",
    "        if player['full_name'].lower() == player_name.lower():\n",
    "            player_id = player['id']\n",
    "            break\n",
    "\n",
    "    if player_id is None:\n",
    "        print(\"Player not found.\")\n",
    "        return\n",
    "\n",
    "    # Seasons to retrieve data for\n",
    "    seasons = ['2024-25', '2023-24']\n",
    "\n",
    "    # Get player game logs for these seasons\n",
    "    player_data = get_player_gamelog(player_id, seasons)\n",
    "\n",
    "    # Calculate player averages against each team\n",
    "    roster_averages = calculate_averages_vs_teams(player_data)\n",
    "\n",
    "    # Train the neural network model\n",
    "    nn_model, scaler = train_neural_network(roster_averages.drop(columns=['OPPONENT', 'Win_Loss_Ratio']),\n",
    "                                            roster_averages[['PTS', 'REB', 'AST']])\n",
    "\n",
    "    # Input the opposing team's abbreviation\n",
    "    opponent_abbreviation = input(\"Enter the opposing team's abbreviation (e.g., LAL for Lakers): \")\n",
    "\n",
    "    # Predict player stats against the opposing team\n",
    "    predictions = predict_player_stats_nn(nn_model, scaler, roster_averages, opponent_abbreviation)\n",
    "\n",
    "    # Display predictions\n",
    "    if predictions is not None:\n",
    "        print(f\"\\nPredicted stats against {opponent_abbreviation}:\")\n",
    "        for i in range(len(predictions)):\n",
    "            print(f\"Player {i+1}: PTS: {predictions[i][0]:.2f}, REB: {predictions[i][1]:.2f}, AST: {predictions[i][2]:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Model\n",
    "import pandas as pd\n",
    "from nba_api.stats.endpoints import playergamelog\n",
    "from nba_api.stats.static import players\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Step 1: Get player game log stats for the last 5 years\n",
    "def get_player_gamelog(player_id, seasons):\n",
    "    all_games = []\n",
    "    for season in seasons:\n",
    "        gamelog = playergamelog.PlayerGameLog(player_id=player_id, season=season).get_data_frames()[0]\n",
    "        all_games.append(gamelog)\n",
    "    return pd.concat(all_games, ignore_index=True)\n",
    "\n",
    "# Step 2: Calculate averages for each player against each team\n",
    "def calculate_averages_vs_teams(player_data):\n",
    "    player_data['OPPONENT'] = player_data['MATCHUP'].apply(lambda x: x.split()[2])\n",
    "    player_data['WL'] = player_data['WL'].map({'W': 1, 'L': 0})\n",
    "    \n",
    "    averages = player_data.groupby('OPPONENT').agg({\n",
    "        'WL': 'mean',\n",
    "        'MIN': 'mean',\n",
    "        'FGM': 'mean',\n",
    "        'FGA': 'mean',\n",
    "        'FG_PCT': 'mean',\n",
    "        'FG3M': 'mean',\n",
    "        'FG3A': 'mean',\n",
    "        'FG3_PCT': 'mean',\n",
    "        'FTM': 'mean',\n",
    "        'FTA': 'mean',\n",
    "        'FT_PCT': 'mean',\n",
    "        'OREB': 'mean',\n",
    "        'DREB': 'mean',\n",
    "        'REB': 'mean',\n",
    "        'AST': 'mean',\n",
    "        'STL': 'mean',\n",
    "        'BLK': 'mean',\n",
    "        'TOV': 'mean',\n",
    "        'PF': 'mean',\n",
    "        'PTS': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    averages.rename(columns={'WL': 'Win_Loss_Ratio'}, inplace=True)\n",
    "    return averages\n",
    "\n",
    "# Step 3: Train SVM model with k-fold cross-validation\n",
    "def train_svm_model(averages):\n",
    "    # Prepare the features and target variables\n",
    "    features = averages.drop(columns=['OPPONENT', 'Win_Loss_Ratio'])\n",
    "    targets = averages[['PTS', 'REB', 'AST']]\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # Define the SVM model and parameter grid for tuning\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
    "        'epsilon': [0.1, 0.2, 0.5],\n",
    "        'kernel': ['linear', 'rbf', 'poly']  # Experiment with different kernels\n",
    "    }\n",
    "\n",
    "    # Use GridSearchCV for hyperparameter tuning with k-fold cross-validation\n",
    "    best_models = {}\n",
    "    for stat in ['PTS', 'REB', 'AST']:\n",
    "        model = SVR()\n",
    "        grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "        grid_search.fit(features_scaled, targets[stat])\n",
    "        \n",
    "        best_models[stat] = grid_search.best_estimator_\n",
    "        print(f'Best parameters for {stat}: {grid_search.best_params_}')\n",
    "        \n",
    "        # Evaluate the model using k-fold cross-validation\n",
    "        cv_scores = cross_val_score(best_models[stat], features_scaled, targets[stat], cv=5, scoring='neg_mean_squared_error')\n",
    "        mse_scores = -cv_scores  # Convert to positive MSE\n",
    "        print(f'Cross-Validation MSE for {stat}: {mse_scores.mean():.2f} +/- {mse_scores.std():.2f}')\n",
    "\n",
    "    return best_models, scaler\n",
    "\n",
    "# Step 4: Predict player stats against the opposing team\n",
    "def predict_player_stats(models, scaler, averages, opponent_abbreviation):\n",
    "    opponent_data = averages[averages['OPPONENT'] == opponent_abbreviation]\n",
    "    if opponent_data.empty:\n",
    "        print(f\"No data available for opponent: {opponent_abbreviation}\")\n",
    "        return None\n",
    "\n",
    "    # Scale the features for prediction\n",
    "    features = opponent_data.drop(columns=['OPPONENT', 'Win_Loss_Ratio'])\n",
    "    features_scaled = scaler.transform(features)\n",
    "\n",
    "    predictions = {}\n",
    "    for stat in ['PTS', 'REB', 'AST']:\n",
    "        predicted_values = models[stat].predict(features_scaled)\n",
    "        predictions[stat] = predicted_values\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "\n",
    "\n",
    "\n",
    "    # Get player and team data\n",
    "    player_name = input(\"Enter a player's full name (e.g., LeBron James): \")\n",
    "    nba_players = players.get_players()\n",
    "\n",
    "    # Find player ID\n",
    "    player_id = None\n",
    "    for player in nba_players:\n",
    "        if player['full_name'].lower() == player_name.lower():\n",
    "            player_id = player['id']\n",
    "            break\n",
    "\n",
    "    if player_id is None:\n",
    "        print(\"Player not found.\")\n",
    "        return\n",
    "\n",
    "    # Seasons to retrieve data for\n",
    "    seasons = ['2024-25','2023-24','2022-23', '2021-22']\n",
    "\n",
    "    # Get player game logs for these seasons\n",
    "    player_data = get_player_gamelog(player_id, seasons)\n",
    "\n",
    "    # Calculate player averages against each team\n",
    "    roster_averages = calculate_averages_vs_teams(player_data)\n",
    "\n",
    "    # Train the SVM model\n",
    "    models, scaler = train_svm_model(roster_averages)\n",
    "\n",
    "    # Input the opposing team's abbreviation\n",
    "    opponent_abbreviation = input(\"Enter the opposing team's abbreviation (e.g., LAL for Lakers): \")\n",
    "    \n",
    "    # Predict player stats against the opposing team\n",
    "    predictions = predict_player_stats(models, scaler, roster_averages, opponent_abbreviation)\n",
    "\n",
    "    # Display predictions\n",
    "    if predictions:\n",
    "        print(f\"\\nPredicted stats against {opponent_abbreviation}:\")\n",
    "        for i in range(len(predictions['PTS'])):\n",
    "            print(f\"Player {i+1}: PTS: {predictions['PTS'][i]:.2f}, REB: {predictions['REB'][i]:.2f}, AST: {predictions['AST'][i]:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
